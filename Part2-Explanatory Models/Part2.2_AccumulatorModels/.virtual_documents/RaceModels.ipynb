import numpy as np
import random as rnd
import matplotlib.pyplot as plt
import scipy.stats as stat
import scipy
import seaborn as sns
import pandas as pd
import math
from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)
sns.set_style("whitegrid")





class race():
    """
    Simulate a race diffusion Model.
    """

    def __init__(self, A=1.0, v=[1], z=None, s=1, ter=0.3, dt=0.01):
        # Simulation parameters
        self.v = v      # Evidence accumulation rates
        self.A = A      # Decision threshold
        self.s = s      # Noise in accumulation
        self.ter = ter  # Non-decision time (e.g., perception and motor execution)
        self.dt = dt

    def run(self, max_time = 10):
        """Runs a trial"""
        # Set up
        rates = self.v
        noise = self.s
        t = self.ter/self.dt
        threshold = self.A
        time = self.ter
        dt = self.dt

        # Storing variables
        rt = 0
        choice = None
        
        E = [np.zeros(len(rates))]
        
        for i in range(int(t)):
            E.append(np.zeros(len(rates)))  # Starting point for evidence accumulation
        
        # Process
        
        while choice is None and time < max_time:
            newE = np.zeros(len(rates))
            oldE = E[-1]
            for i, drift in enumerate(rates):
                dE = np.random.normal(drift * dt, (noise**2) * np.sqrt(dt))
                newE[i] = oldE[i] + dE 
                if newE[i] > threshold:
                    choice = i
            E.append(newE)
            time += dt

        if choice is not None:
            rt = time
        else:
            rt = time      # Indicates timeout
            choice = np.nan  # No decision made

        return (E, rt, choice)






model = race(v=[0.2, 1, 0.7, 0.5], ter=0, dt=0.005)
E, rt, choice = model.run()
xtime = np.arange(0, rt + model.dt/2, model.dt)
plt.figure(figsize=(5,3))
plt.plot(xtime, E, alpha=0.75)
plt.plot(rt, model.A, "o")
plt.title("Evidence Accumulation in a Race Model")
plt.xlabel("Time (seconds)")
plt.ylabel("Evidence")
plt.axhline(y=1, color='k', linestyle='--', alpha=1)
plt.savefig("figures/race_example.png")
plt.show()


model = race(v=[1.5, 1, 0.8], dt=0.0025, ter=0)
E, rt, choice = model.run()
xtime = np.arange(0, rt + model.dt/2, model.dt)
plt.figure(figsize=(5,3))
plt.plot(xtime, E, alpha=0.75)
plt.plot(rt, model.A, "o")
plt.title("Evidence Accumulation in a Race Model")
plt.xlabel("Time (seconds)")
plt.ylabel("Evidence")
plt.axhline(y=1, color='k', linestyle='--', alpha=1)
plt.savefig("figures/race_example.png")
plt.show()





E = np.array(E)
x = E[:,0]
y = E[:,1]
z = E[:,2]

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot(xs=x, ys=y, zs=z, linestyle="-", linewidth=0.5)
ax.plot(xs=x[0], ys=y[0], zs=z[0], marker="o")
ax.plot(xs=x[-1], ys=y[-1], zs=z[-1], marker="*")
ax.view_init(elev=30, azim=240)
ax.set_xlabel("x")
ax.set_ylabel("y")
ax.set_zlabel("z")
plt.savefig("drift_3D.png")








class lca():
    """
    Simulate a LCA model.
    """

    def __init__(self, A=1.0, v=[1], kappa=0.1, beta=0.01, s=1, ter=0.3, dt=0.01):
        # Simulation parameters
        self.v = v      # Evidence accumulation rates
        self.A = A      # Decision threshold
        self.s = s      # Noise in accumulation
        self.ter = ter  # Non-decision time (e.g., perception and motor execution)
        self.dt = dt
        self.kappa = kappa
        self.beta = beta

    def run(self, max_time = 10):
        """Runs a trial"""
        # Set up
        rates = self.v
        N = len(rates)
        noise = self.s
        k = self.kappa
        b = self.beta
        t = self.ter/self.dt
        threshold = self.A
        time = self.ter
        dt = self.dt

        # Storing variables
        rt = 0
        choice = None
        
        E = [np.zeros(N)]
        
        for i in range(int(t)):
            E.append(np.zeros(N))  # Starting point for evidence accumulation
        
        # Process
        
        while choice is None and time < max_time:
            newE = np.zeros(N)
            oldE = E[-1]
            for i, drift in enumerate(rates):
                mask = np.ones(N)
                mask[i] = 0
                Inpt = np.random.normal(drift*dt, (noise**2) * np.sqrt(dt))
                Leak = oldE[i] * k * dt
                Cmpt = np.sum(oldE * mask * b) * dt
                dE = Inpt - Leak - Cmpt
                newE[i] = oldE[i] + dE 
                if newE[i] > threshold:
                    choice = i
            E.append(newE)
            time += dt

        if choice is not None:
            rt = time
        else:
            rt = time      # Indicates timeout
            choice = np.nan  # No decision made

        return (E, rt, choice)



z = np.zeros(5)
o = np.ones(5)
z * o





model = lca(v=[1, 0.2, 0.3], kappa = 0, beta=3, dt=0.001)
E, rt, choice = model.run()
xtime = np.arange(0, rt + model.dt/2, model.dt)
plt.figure(figsize=(5,3))
plt.plot(xtime, E, alpha=0.75)
plt.xlim(0, 1)
plt.plot(rt, model.A, "o")
plt.suptitle("Evidence Accumulation in an LCA Model")
plt.title(r"$\kappa = %.2f$, $\beta = %.2f$" % (model.kappa, model.beta))
plt.xlabel("Time (seconds)")
plt.ylabel("Evidence")
plt.axhline(y=1, color='k', linestyle='--', alpha=1)
plt.tight_layout()
plt.savefig("figures/lca_example.png")
plt.show()


E = np.array(E)
x = E[:,0]
y = E[:,1]
z = E[:,2]

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot(xs=x, ys=y, zs=z, linestyle="-", linewidth=0.5)
ax.plot(xs=x[0], ys=y[0], zs=z[0], marker="o")
ax.plot(xs=x[-1], ys=y[-1], zs=z[-1], marker="*")
ax.view_init(elev=30, azim=140)
ax.set_xlabel("x")
ax.set_ylabel("y")
ax.set_zlabel("z")
ax.set_xlim(-1, 1)
ax.set_ylim(-1, 1)
ax.set_zlim(-1, 1)

plt.savefig("drift_3D_LCA.png")





class LBA:
    """Brown and Heathcote's Linear Ballistic Accumulator""" 
    def __init__(self, v=1, a=1, ter=0.3, vsd=0.1):
        """Initializes the main parameters"""
        self.v = v
        self.a = a
        self.ter = ter
        self.vsd = vsd
        
    def run(self, max_time = 5):
        """Simulates a single trial as a random ray"""
        slope = np.max((0.000000001, np.random.normal(self.v, self.vsd)))
        start = np.random.uniform(0, self.a)
        intersect = (self.a - start) / slope
        rt = np.min((max_time, self.ter + intersect))         
        return (rt, slope, start)
    






lba = LBA(v = 0.75, a = 1, ter=0.3, vsd=0.3)

N= 1000
trials = []
for i in range(N):
    trials.append(lba.run())

rts = [x[0] for x in trials]
ks = [x[2] for x in trials]
data = pd.DataFrame({"rts":rts})
#sns.kdeplot(data=data, fill=True)

fig, (axs1, axs2) = plt.subplots(2, 1, figsize=(6,4), gridspec_kw={'height_ratios': [1, 1]})
max_time = 3

axs1.set_xlim(0, max_time)
axs2.set_xlim(0, max_time)

for ax in (axs1,):#, axs3):
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax.axis('off')

axs2.set_ylim(-0.2, lba.a + 0.2)
axs2.set_ylabel("Evidence")
axs2.set_xlabel("Time")

# The traces

axs2.plot([0, max_time], [lba.a, lba.a], '--')
axs2.plot([0, max_time], [0, 0], '--')
axs2.plot([0, lba.ter], [0, 0], "k")

axs2.text(s=r"$Ter$", x=lba.ter/2, y = 0, ha='center', va = 'bottom')
axs2.text(s=r"$A$", x=max_time - 0.5, y = lba.a, ha='center', va = 'top')

subset = rnd.sample([x for x in trials if x[0] < max_time], k = 10)

for trace in subset:
    rt, v, k = trace
    axs2.plot([lba.ter, rt], [k, lba.a], alpha=0.5)

bins = [x/2 for x in range(0, 2*max_time)]
axs2.set_title(r"$v = %.2f$, $A = %.2f$, $Ter = %.1f$" % (lba.v, lba.a, lba.ter)) 
kwargs = dict(histtype='stepfilled', alpha=0.2, density=False, bins=bins, ec="k")
sns.kdeplot(data=data, x='rts', ax=axs1, fill=True, bw=0.2)
fig.suptitle("Brown & Heathcote's Linear Ballistic Accumulator")
fig.tight_layout()
#plt.savefig("figures/lba.png", dpi=200)
plt.show()

#print(np.mean(rts))
#print(0.3 + 0.5/0.75)





data = pd.read_csv('simon_data.csv')
data





ax = sns.histplot(data, x="RT", kde=True)
ax.set_title("Histogram of Response Times from Simon Task")
plt.show()





empirical_kde = stat.gaussian_kde(data.RT, bw_method=1)
x = np.linspace(0, 10000, 100)
empirical_dist = [empirical_kde(i) for i in x]
plt.plot(x, empirical_dist)
plt.title("Empirical Distribution of RTs from KDE")
plt.xlabel("RT")
plt.ylabel("Probability")
plt.show()





def loss(X):
    v, ter, a, vsd = X 
    lba = LBA(v = v, ter=ter, a= a, vsd = vsd)
    traces = [lba.run(max_time=30) for i in range(1000)]
    predicted = [x[0]*1000 for x in traces]
    model_kde = stat.gaussian_kde(np.array(predicted))
    model_dist = [model_kde(x) for x in np.linspace(0, 10000, 100)]
    
    return np.min((stat.entropy(empirical_dist, model_dist)[0], 10**2))

aspace = np.linspace(0.1, 0.6, 11)
vspace = np.linspace(0.1, 0.6, 11)
matrix = np.zeros((len(aspace), len(vspace)))

for i, a in enumerate(aspace):
    for j, v in enumerate(vspace):
        matrix[i,j] = loss(np.array([v, 0.25, a, 0.25]))
matrix


lba = LBA(v = 0.7, ter=0.2, a= 0.5, vsd = 0.1)
traces = [lba.run(max_time=30) for i in range(1000)]
predicted = [x[0]*1000 for x in traces]
model_kde = stat.gaussian_kde(np.array(predicted))
model_dist = [model_kde(x) for x in np.linspace(0, 10000, 100)]
stat.entropy(empirical_dist, model_dist)[0]








fig = plt.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(matrix, interpolation='nearest')
fig.colorbar(cax)

ax.xaxis.set_major_locator(MultipleLocator(1))
ax.yaxis.set_major_locator(MultipleLocator(1))
ax.set_xticklabels([''] + [str(round(x, 2)) for x in aspace])
ax.set_yticklabels([''] + [str(round(x, 2)) for x in vspace])
ax.set_xlabel(r"Decision boundary $A$ ")
ax.set_ylabel(r"Drift rate $v$ ")
ax.set_title("KL Divergence of LBA Model by Parameter Combination")
plt.show()





res = scipy.optimize.minimize(loss, x0=[0.5, 0.5, 1, 0.5],
                              method="Powell", bounds=[[0.1, 1], 
                                                       [0.1, 0.3], 
                                                       [0.0001, 0.5],
                                                       [0.0001, 0.5]],
                             tol=0.1)
print(res)





# Generate high-density RT space for better viz
rtx = np.linspace(0, 10000, 100)

# Re-generate empirical RT Distribution

empirical_dist = [empirical_kde(i) for i in rtx]
empirical_dist = np.array(empirical_dist).reshape(100)

# RT Dist with default values

lba = LBA(v=3, ter=2, a=1, vsd=0.1)
traces = [lba.run(max_time=100) for i in range(10000)]
predicted = [x[0]*1000 for x in traces]
labdist = stat.gaussian_kde(predicted)
default_dist = [labdist(i) for i in rtx]

# RT Dist with Optimized values

vstar, terstar, astar, vsdstar = res.x
print(res.x)

lbastar = LBA(v=vstar, ter=terstar, a=astar, vsd=vsdstar)
traces = [lbastar.run(max_time=100) for i in range(5000)]
predicted = [x[0]*1000 for x in traces]
labdist = stat.gaussian_kde(predicted, bw_method=0.5)
optimized_dist = [labdist(i) for i in rtx]
optimized_dist = np.array(optimized_dist).reshape(100)

# Compute KL

kl = stat.entropy(empirical_dist, optimized_dist)

plt.plot(rtx, empirical_dist, label="Empirical Data")
plt.fill_between(x=rtx, y1=empirical_dist, alpha=0.1)
#plt.plot(rtx, default_dist, label="LBA Prediction (Default Parameters)")

plt.plot(rtx, optimized_dist, label="LBA Prediction (Fitted Parameters)")
plt.fill_between(x=rtx, y1=optimized_dist, alpha=0.5)

plt.legend()
plt.suptitle("LBA Fitting ($KL = %.2f$)" % (kl))
plt.title("$v = %.2f, T_{ER} = %.2f, A= %.2f, SD_v = %.2f$" % (vstar, terstar, astar, vsdstar))
plt.xlabel("RT")
plt.ylabel("Probability")
plt.show()














fig, (axs1, axs2) = plt.subplots(2, 1, figsize=(6,4), gridspec_kw={'height_ratios': [1, 2]})

max_time = 1.5

axs1.set_xlim(0, max_time)
axs2.set_xlim(0, max_time)
#axs3.set_xlim(0, max_time)

for ax in (axs1,):#, axs3):
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax.axis('off')
    #ax.set_ylim(0, 2000)`
    #axs3.set_ylim(0, 10)

axs2.set_ylim(-0.2, model.A + 0.2)
axs2.set_ylabel("Evidence")
axs2.set_xlabel("Time")

# The traces

axs2.plot([0, model.ter], [model.z, model.z], "k")
axs2.plot([0, max_time], [model.A, model.A], '--')
axs2.plot([0, max_time], [0, 0], '--')

axs2.text(s=r"$Ter$", x=model.ter/2, y = model.z, ha='center', va = 'top')
axs2.text(s=r"$A$", x=max_time - 0.5, y = model.A, ha='center', va = 'top')
#axs2.text(s=r"$0$", x=max_time - 0.5, y = 0, ha='center', va = 'bottom')

traces = rnd.choices(runs, k=10)

sns.kdeplot(data, x="rts", hue="choices", ax=axs1, fill=True)

for trace in traces:
    n = len(trace)
    if trace[-1] > model.A:
        trace[-1] = model.A
    elif trace[-1] < 0:
        trace[-1] = 0
    x = np.arange(model.ter + model.dt, model.ter + model.dt * (n+1/2), model.dt)
    axs2.plot(x, trace, linewidth=0.75)

axs2.set_title(r"$v = %.2f$, $A = %.2f$, $Ter = %.1f$" % (model.v, model.A, model.ter)) 
kwargs = dict(histtype='stepfilled', alpha=0.2, density=False, bins=bins, ec="k")

fig.suptitle("Ratcliff's Drift-Diffusion Model")
fig.tight_layout()
plt.show()
plt.savefig('figures/newddm.jpg')





1 / (1 + np.exp(-1))




import os
import random
import numpy as np
import scipy.optimize as opt
import scipy.stats as stat
from scipy.spatial.distance import cdist
import statsmodels.api as sm
import sklearn as sk
import sklearn.cluster as clust
from sklearn.metrics import RocCurveDisplay
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, roc_auc_score, roc_curve

import matplotlib.pyplot as plt
import pandas as pd
from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)
#from tqdm.notebook import tqdm
import seaborn as sns
sns.set(style="whitegrid")





data = pd.read_csv("../../holly.csv")
data





ax = sns.scatterplot(data, x="age", y="sof", hue="clinicalStatus", s=60)
ax.set_title("Holly's Data: True Categories")
plt.show()





dataX = data[["age","sof"]]
dataX





dataX['age_zscore'] = (dataX.age - dataX.age.mean()) / dataX.age.std(ddof=0)
dataX['sof_zscore'] = (dataX.sof - dataX.sof.mean()) / dataX.sof.std(ddof=0)
dataZ = dataX[['age_zscore','sof_zscore']]
dataX = dataX[['age','sof']]
dataZ








classes = [0 if x == "HC" else 1 for x in data.clinicalStatus ]
ax=sns.scatterplot(data, y="clinicalStatus", x="sof", s=60, hue="clinicalStatus")
plt.show()


newobs = [80, 0.35]
newobs_z = [(newobs[0] - data.age.mean())/data.age.std(),
            (newobs[1] - data.sof.mean())/data.sof.std()]
x, y = newobs_z
point = pd.DataFrame({"age":newobs[:-1], "sof":newobs[1:]}) #np.array([newobs]).reshape((1,2))
point_z = pd.DataFrame({"age_zscore":newobs_z[:-1], "sof_zscore":newobs_z[1:]}) #np.array([newobs]).reshape((1,2))





lm = sk.linear_model.LinearRegression()
lm.fit(dataX[['sof']], classes)
data['class'] = classes
ax = sns.scatterplot(data, y="class", x="sof", s=60, hue="clinicalStatus")
b0 = lm.intercept_
b1 = lm.coef_[0]
x = np.linspace(0.3, 0.5)
pred = b0 + b1 * x
ax.plot(x, pred)
ax.set_title("Linear Regression")

xpred = point[['sof']]
ypred = lm.predict(point[['sof']])
ax.text(newobs[1], ypred+0.1, s="New observation", color="magenta")
ax.scatter(xpred, ypred, s=100, color='magenta')
plt.show()





logm = sk.linear_model.LogisticRegression(penalty=None, fit_intercept=True, max_iter=1000)
logm.fit(data[['sof']], classes)

# Create predictions for arbitrary values
newx = pd.DataFrame({'sof':list(np.linspace(0.3, 0.5))})
newy = logm.predict_proba(newx)

ax=sns.scatterplot(data, y="class", x="sof", s=60, hue="clinicalStatus")
ax.plot(newx, newy[:,1])
ax.set_title("Logistic Regression")
plt.show()





logm = sk.linear_model.LogisticRegression(penalty=None, fit_intercept=True, max_iter=1000)
logm.fit(dataZ, classes)

fig, ax = plt.subplots(1)
RocCurveDisplay.from_estimator(logm, dataZ, classes, ax=ax, plot_chance_level=True)
ax.set_aspect('equal')
ax.set_title("ROC for Logistic classifier (Holly's data)")
plt.show()





X_train, X_test, y_train, y_test = train_test_split(dataX, classes, random_state=0)
logm.fit(X_train, y_train)
fig, ax = plt.subplots(1)
y_predict = logm.predict(X_test)
RocCurveDisplay.from_predictions(y_test, y_predict, ax=ax, pos_label=None, plot_chance_level=True)
ax.set_aspect('equal')
ax.set_title("ROC for Logistic classifier (Holly's test data)")
plt.show()


svm = sk.svm.LinearSVC()
svm.fit(dataX, classes)


fig, ax = plt.subplots(1)
RocCurveDisplay.from_estimator(svm, dataX, classes, ax=ax, plot_chance_level=True)


X_train, X_test, y_train, y_test = train_test_split(dataX, classes, random_state=0)
svm.fit(X_train, y_train)
fig, ax = plt.subplots(1)
y_predict = logm.predict(X_test)
RocCurveDisplay.from_predictions(y_test, y_predict, ax=ax, pos_label=None, plot_chance_level=True)
ax.set_aspect('equal')
ax.set_title("ROC for Logistic classifier (Holly's test data)")
plt.show()









# Load the data
df = pd.read_csv("../../holly_extended.csv")

df['sex'] = df['sex'].str.strip().str.lower()
df['diagnosis'] = df['clinicalStatus'].str.strip().str.lower()

# Define robust mappings
sex_map = {'m': 0, 'male': 0, 'f': 1, 'female': 1}
diagnosis_map = {'hc': 0, 'healthy': 0, 'mci': 1}

# Map strings to integers with .map()
df['sex'] = df['sex'].map(sex_map)
df['diagnosis'] = df['diagnosis'].map(diagnosis_map)

# Target and features
y = df['diagnosis'].values
X = df.drop(columns=['diagnosis', 'clinicalStatus', 'participant', 'userId'])

# Optional: clean or encode categorical columns
X = pd.get_dummies(X, drop_first=True)

# Replaces NAs with means
X = X.fillna(X.mean())

# Feature names
feature_names = X.columns.tolist()

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split: 60% train, 20% val, 20% test
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)

# LASSO logistic regression
lasso = LogisticRegression(penalty='l1', solver='liblinear', C=1.0)
lasso.fit(X_train, y_train)

# Predict probabilities
y_val_prob = lasso.predict_proba(X_val)[:, 1]
y_test_prob = lasso.predict_proba(X_test)[:, 1]

# ROC curves
fpr_val, tpr_val, _ = roc_curve(y_val, y_val_prob)
fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)

plt.figure(figsize=(8, 6))
plt.plot(fpr_val, tpr_val, label=f'Validation AUC = {roc_auc_score(y_val, y_val_prob):.2f}')
plt.plot(fpr_test, tpr_test, label=f'Test AUC = {roc_auc_score(y_test, y_test_prob):.2f}')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Classification report
print("Validation Performance:")
print(classification_report(y_val, lasso.predict(X_val)))
print("Test Performance:")
print(classification_report(y_test, lasso.predict(X_test)))

# Feature importance (non-zero coefficients)
coef = lasso.coef_.flatten()
important_idx = np.where(coef != 0)[0]
important_features = [feature_names[i] for i in important_idx]
important_weights = coef[important_idx]

# Bar plot of feature importances
plt.figure(figsize=(10, 6))
sns.barplot(x=important_weights, y=important_features, orient='h', palette="viridis")
plt.title("Important Features (LASSO Coefficients â‰  0)")
plt.xlabel("Coefficient Weight")
plt.ylabel

